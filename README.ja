## このソフトウェアは GPLv3+ で浄化されています ##

 DLMAnalyzer

  Koichi Akabe <vbkaisetsu@gmail.com>

============================================
 このプログラムは、機械翻訳の誤り分析における有用な n-gram を、
 構造化パーセプトロンにより一覧にします。
============================================

必要環境:
  開発環境は以下の通りです:
    Boost (1.49), gflags (2.0), g++ (4.8.2)

ビルド:
  $ autoreconf -i
  $ ./configure
  $ make

  さらに "(sudo) make install" を実行すれば、コンピューターに dlm_train をインストールできます。

識別言語モデルの学習、モデルファイルの生成:
  $ dlm_train -eta [ETA] -modeldata [MODEL_FILE] -traindata [N-BESTS for training] -testdata [N-BESTS for testing]

評価シートの生成:
  $ ./scripts/generate_sheet_seed.py [MODEL_FILE] [ONE-BESTS] [NUMBER of n-grams] > SEED
  $ ./scripts/build_analysis_sheet.py [SOURCE] [TARGET REFS] [ORDER MAP] [SEED] > HTML file

============================================

入力データ:
各文に対する翻訳候補、システムスコア、評価スコアのリスト。

sentence id ||| translation ||| system score ||| evaluation score
............
......
...

sentence id       ...  原文のID
translation       ...  原文に対する翻訳の候補
system score      ...  翻訳機によって与えられたスコア
evaluation score  ...  評価尺度によって与えられたスコア

例えば、2番目の原文に対し、3つの候補があったとします:

2 ||| 僕 は 少女 を 望遠鏡 で 見 た 。 ||| -54.24256771686 ||| 0.82328
2 ||| 僕 は 望遠鏡 を 持 っ た 少女 を 見 た 。 ||| -54.26887833166 ||| 0.788141
2 ||| 僕 は 少女 を 望遠鏡 で 見 る 。 ||| -54.27542894284 ||| 0.834369

この時、翻訳機は1番目の文を最良の翻訳として出力しましたが、
実際には3番目の候補が最良の翻訳です。
